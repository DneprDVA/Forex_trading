{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talib\n",
    "import MetaTrader5 as mt  \n",
    "import pandas as pd  \n",
    "import time\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.optim import lr_scheduler\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "from numpy import array\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AccountInfo(login=51225190, trade_mode=0, leverage=500, limit_orders=500, margin_so_mode=0, trade_allowed=True, trade_expert=True, margin_mode=2, currency_digits=2, fifo_close=False, balance=99.11, credit=0.0, profit=2.67, equity=101.78, margin=2.13, margin_free=99.65, margin_level=4778.403755868545, margin_so_call=50.0, margin_so_so=20.0, margin_initial=0.0, margin_maintenance=0.0, assets=0.0, liabilities=0.0, commission_blocked=0.0, name='Dneprovskii Vladimir', server='Alpari-MT5-Demo', currency='USD', company='Alpari')\n"
     ]
    }
   ],
   "source": [
    "mt.initialize()\n",
    "login = 51225190\n",
    "password = 'W5bu8LY1V'\n",
    "server = 'Alpari-MT5-Demo'\n",
    "\n",
    "mt.login(login, password, server)\n",
    "# get account info\n",
    "account_info = mt.account_info()\n",
    "print(account_info)\n",
    "\n",
    "# getting specific account data\n",
    "login_number = account_info.login\n",
    "balance = account_info.balance\n",
    "equity = account_info.equity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=300, num_layers=1, device=device):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.device = device\n",
    "        # self.num_classes = num_classes #number of classes\n",
    "        self.num_layers = num_layers #number of layers\n",
    "        self.input_size = input_size #input size\n",
    "        self.hidden_size = hidden_size #hidden state        \n",
    "        self.BatchNorm = nn.BatchNorm1d(32, affine=False)\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                          num_layers=num_layers, batch_first=True)\n",
    "        self.fc_2 =  nn.Linear(hidden_size, 64) \n",
    "        self.fc_1 =  nn.Linear(64, 32) \n",
    "        self.fc = nn.Linear(32, 1) \n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        h_0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(self.device) #hidden state Variable(\n",
    "        c_0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(self.device) #internal state Variable(\n",
    "        h_0 = self.BatchNorm(h_0)\n",
    "        c_0 = self.BatchNorm(c_0)\n",
    "        # Propagate input through LSTM\n",
    "        output, (hn, cn) = self.lstm(x, (h_0, c_0)) #lstm with input, hidden, and internal state\n",
    "        hn = hn.view(-1, self.hidden_size) #reshaping the data for Dense layer next\n",
    "        out = self.relu(hn)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc_2(out) #first Dense\n",
    "        out = self.relu(out) #relu\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc_1(out) #first Dense\n",
    "        out = self.relu(out) #relu\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out) #Final Output\n",
    "        return out\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df_x):\n",
    "        self.data_x = df_x         \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_x)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        feature = torch.from_numpy(self.data_x[index]).float()        \n",
    "        return feature\n",
    "\n",
    "input_size_M15 = 24\n",
    "\n",
    "model_M15 = LSTM(input_size_M15, device=device)\n",
    "model_M15.to(device)\n",
    "PATH_M15 = \"C:/Users/vovad/Desktop/Trading/models/model_M15_1/model_7.pth\"\n",
    "checkpoint_M15 = torch.load(PATH_M15, map_location=device)\n",
    "lr_M15 = 0.00001\n",
    "loss_fn = nn.BCEWithLogitsLoss().to(device)\n",
    "optimizer_M15 = torch.optim.Adam(model_M15.parameters(), lr=lr_M15)\n",
    "model_M15.load_state_dict(checkpoint_M15['model_state_dict'])\n",
    "optimizer_M15.load_state_dict(checkpoint_M15['optimizer_state_dict'])\n",
    "epoch_M15 = checkpoint_M15['epoch']\n",
    "loss_M15 = checkpoint_M15['loss']\n",
    "\n",
    "scaler_M15 = MinMaxScaler()\n",
    "ct_M15 = ColumnTransformer(\n",
    "        remainder='passthrough', \n",
    "        transformers=[\n",
    "            ('mm', scaler_M15, [0,23])\n",
    "        ])\n",
    "\n",
    "input_size_M5 = 23\n",
    "\n",
    "model_M5 = LSTM(input_size_M5, device=device)\n",
    "model_M5.to(device)\n",
    "PATH_M5 = \"C:/Users/vovad/Desktop/Trading/models/model_M5_1/model_7.pth\"\n",
    "checkpoint_M5 = torch.load(PATH_M5, map_location=device)\n",
    "lr_M5 = 0.00001\n",
    "loss_fn = nn.BCEWithLogitsLoss().to(device)\n",
    "optimizer_M5 = torch.optim.Adam(model_M5.parameters(), lr=lr_M5)\n",
    "model_M5.load_state_dict(checkpoint_M5['model_state_dict'])\n",
    "optimizer_M5.load_state_dict(checkpoint_M5['optimizer_state_dict'])\n",
    "epoch_M5 = checkpoint_M5['epoch']\n",
    "loss_M5 = checkpoint_M5['loss']\n",
    "\n",
    "scaler_M5 = MinMaxScaler()\n",
    "ct_M5 = ColumnTransformer(\n",
    "        remainder='passthrough', \n",
    "        transformers=[\n",
    "            ('mm', scaler_M5, [0,22])\n",
    "        ])\n",
    "        \n",
    "def split_sequences(sequences, n_steps):\n",
    "    X = []\n",
    "    for i in range(len(sequences)):        \n",
    "        end_ix = i + n_steps        \n",
    "        if end_ix > len(sequences):\n",
    "            break        \n",
    "        seq_x = sequences[i:end_ix, :]\n",
    "        X.append(seq_x)        \n",
    "    return array(X)\n",
    "    \n",
    "def get_predictions(model, data_loader):\n",
    "    model.eval()\n",
    "    y_pred_list = []    \n",
    "    with torch.inference_mode():\n",
    "        for X_batch in data_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_tag = y_pred_tag.long()\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())            \n",
    "\n",
    "    predictions = [a.squeeze().tolist() for a in y_pred_list]\n",
    "    predictions = sum(predictions, [])\n",
    "    return predictions\n",
    "\n",
    "def dataset_import_M15():    \n",
    "    dataset = mt.copy_rates_from_pos(\"EURUSD_i\", mt.TIMEFRAME_M15, 0, 722)    \n",
    "    dataset = pd.DataFrame(dataset, columns=['open', 'high', 'low', 'close'])\n",
    "\n",
    "    dataset['EMA_14'] = talib.EMA(dataset['close'], timeperiod=14)    \n",
    "    dataset['EMA_30'] = talib.EMA(dataset['close'], timeperiod=30)\n",
    "    dataset['EMA_48'] = talib.EMA(dataset['close'], timeperiod=48)   \n",
    "    dataset['upperband'], dataset['middleband'], dataset['lowerband'] = talib.BBANDS(dataset['close'], timeperiod=24, nbdevup=8, nbdevdn=8, matype=0)    \n",
    "    dataset['HT_TRENDLINE'] = talib.HT_TRENDLINE(dataset['close'])\n",
    "    dataset['TEMA_24'] = talib.TEMA(dataset['close'], timeperiod=24)\n",
    "    dataset['TEMA_30'] = talib.TEMA(dataset['close'], timeperiod=30)\n",
    "    dataset['TEMA_48'] = talib.TEMA(dataset['close'], timeperiod=48)\n",
    "    dataset['aroondown'], dataset['aroonup'] = talib.AROON(dataset['high'], dataset['low'], timeperiod=24)\n",
    "    dataset['AROONOSC'] = talib.AROONOSC(dataset['high'], dataset['low'], timeperiod=24)\n",
    "    dataset['HT_DCPERIOD'] = talib.HT_DCPERIOD(dataset['close'])\n",
    "    dataset['HT_TRENDMODE'] = talib.HT_TRENDMODE(dataset['close'])    \n",
    "    dataset['HT_SINE_sine'], dataset['HT_SINE_leadsine']  = talib.HT_SINE(dataset['close'])\n",
    "    dataset['macd'], dataset['macdsignal'], dataset['macdhist'] = talib.MACD(dataset['close'], fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "    dataset['RSI_24'] = talib.RSI(dataset['close'], timeperiod=24)\n",
    "    dataset['NATR_30'] = talib.NATR(dataset['high'], dataset['low'], dataset['close'], timeperiod=30)\n",
    "    dataset['WILLR_30'] = talib.WILLR(dataset['high'], dataset['low'], dataset['close'], timeperiod=30)\n",
    "\n",
    "    dataset = dataset.dropna() \n",
    "\n",
    "    dataset = dataset.reset_index()\n",
    "    dataset = dataset.drop(['index', 'open', 'high', 'low'], axis=1)\n",
    "    dataset = dataset.astype('float32')\n",
    "    dataset = ct_M15.fit_transform(dataset)\n",
    "    n_steps = 550\n",
    "    dataset = split_sequences(dataset, n_steps=n_steps)\n",
    "    print(dataset.shape)\n",
    "    test_dataset = CustomDataset(dataset)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, drop_last=False)\n",
    "    pred = get_predictions(model_M15, test_dataloader)\n",
    "    \n",
    "    return pred, pred[-1] # pred[-3] if pred[-1]!=pred[-2] else pred[-1]\n",
    "\n",
    "def dataset_import_M5():    \n",
    "    dataset = mt.copy_rates_from_pos(\"EURUSD_i\", mt.TIMEFRAME_M5, 0, 372)    \n",
    "    dataset = pd.DataFrame(dataset, columns=['open', 'high', 'low', 'close'])\n",
    "\n",
    "    dataset['EMA_14'] = talib.EMA(dataset['close'], timeperiod=14)    \n",
    "    dataset['EMA_30'] = talib.EMA(dataset['close'], timeperiod=30)\n",
    "    dataset['EMA_48'] = talib.EMA(dataset['close'], timeperiod=48)       \n",
    "    dataset['upperband'], dataset['middleband'], dataset['lowerband'] = talib.BBANDS(dataset['close'], timeperiod=30, nbdevup=10, nbdevdn=10, matype=0)\n",
    "    dataset['TEMA_14'] = talib.TEMA(dataset['close'], timeperiod=14)    \n",
    "    dataset['TEMA_30'] = talib.TEMA(dataset['close'], timeperiod=30)\n",
    "    dataset['TEMA_48'] = talib.TEMA(dataset['close'], timeperiod=48)\n",
    "    dataset['aroondown'], dataset['aroonup'] = talib.AROON(dataset['high'], dataset['low'], timeperiod=24)    \n",
    "    dataset['AROONOSC'] = talib.AROONOSC(dataset['high'], dataset['low'], timeperiod=24)\n",
    "    dataset['HT_DCPERIOD'] = talib.HT_DCPERIOD(dataset['close'])\n",
    "    dataset['HT_TRENDLINE'] = talib.HT_TRENDLINE(dataset['close'])\n",
    "    dataset['HT_TRENDMODE'] = talib.HT_TRENDMODE(dataset['close'])    \n",
    "    dataset['HT_SINE_sine'], dataset['HT_SINE_leadsine']  = talib.HT_SINE(dataset['close'])\n",
    "    dataset['macd'], dataset['macdsignal'], dataset['macdhist'] = talib.MACD(dataset['close'], fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "    dataset['RSI_24'] = talib.RSI(dataset['close'], timeperiod=24)    \n",
    "    dataset['WILLR_30'] = talib.WILLR(dataset['high'], dataset['low'], dataset['close'], timeperiod=30)  \n",
    "    \n",
    "    dataset = dataset.dropna() \n",
    "\n",
    "    dataset = dataset.reset_index()\n",
    "    dataset = dataset.drop(['index', 'open', 'high', 'low'], axis=1)\n",
    "    dataset = dataset.astype('float32')\n",
    "    dataset = ct_M5.fit_transform(dataset)\n",
    "    n_steps = 200\n",
    "    dataset = split_sequences(dataset, n_steps=n_steps)\n",
    "    print(dataset.shape)  \n",
    "    test_dataset = CustomDataset(dataset)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, drop_last=False)\n",
    "    pred = get_predictions(model_M5, test_dataloader)\n",
    "    \n",
    "    return pred, pred[-3] if pred[-1]!=pred[-2] else pred[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 550, 24)\n",
      "(32, 200, 23)\n",
      "[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] \n",
      " [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "X_M15, y_M15 = dataset_import_M15()\n",
    "X_M5, y_M5 = dataset_import_M5()\n",
    "y_M15, y_M5\n",
    "print(X_M15, '\\n', X_M5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b6d089313d9964bf0a775057fdba2ddb76b757f887813491471703a7ee59e2bc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
