{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchmetrics in /root/mambaforge/lib/python3.9/site-packages (0.10.2)\n",
      "Requirement already satisfied: torch>=1.3.1 in /root/mambaforge/lib/python3.9/site-packages (from torchmetrics) (1.11.0)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /root/mambaforge/lib/python3.9/site-packages (from torchmetrics) (1.23.0)\n",
      "Requirement already satisfied: packaging in /root/mambaforge/lib/python3.9/site-packages (from torchmetrics) (21.3)\n",
      "Requirement already satisfied: typing-extensions in /root/mambaforge/lib/python3.9/site-packages (from torch>=1.3.1->torchmetrics) (4.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /root/mambaforge/lib/python3.9/site-packages (from packaging->torchmetrics) (3.0.9)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "95B8PlmSRaMZ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.autograd import Variable \n",
    "from typing import Tuple, Dict, List\n",
    "from torch.optim import lr_scheduler\n",
    "import pathlib\n",
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "import random\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # pip install pandas\n",
    "from numpy import array\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from datetime import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "from numpy import array\n",
    "import re\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1666938040835,
     "user": {
      "displayName": "Владимир Днепровский",
      "userId": "12512107289711404401"
     },
     "user_tz": -180
    },
    "id": "qoHQrssJTP8O",
    "outputId": "a98fa346-01b4-4cc8-8baa-3873a241ddb9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup device-agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/notebooks/CSVs/data_h1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['time'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_sc = data[:85000]\n",
    "data_val_sc = data[85000:120000]\n",
    "data_test_sc = data[120000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = MinMaxScaler()\n",
    "# data_train = scaler.fit_transform(data_train_sc)\n",
    "# data_val = scaler.transform(data_val_sc)\n",
    "# data_test = scaler.transform(data_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L0 = [i for i in data_train['Label'] if i == 0]\n",
    "L1 = [i for i in data_train['Label'] if i == 1]\n",
    "L2 = [i for i in data_train['Label'] if i == 2]\n",
    "total = len(L0) + len(L1) + len(L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.59 6.69 6.88\n"
     ]
    }
   ],
   "source": [
    "cat_0 = (1/(len(L0)/total)/2)\n",
    "cat_1 = (1/(len(L1)/total)/2)\n",
    "cat_2 = (1/(len(L2)/total)/2)\n",
    "\n",
    "print(f'{cat_0:.2f}', f'{cat_1:.2f}', f'{cat_2:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, seq_length):\n",
    "        self.data = df         \n",
    "        self.seq_length = seq_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        start = index - self.seq_length\n",
    "        end = index       \n",
    "        indices = list(range(start, end)) \n",
    "        feature = []\n",
    "        label = []\n",
    "        for i in indices:             \n",
    "            feature_get = self.data.iloc[i, :-1]\n",
    "            # feature_get, labels = self.data.iloc[index, :-1], self.data.iloc[index, -1]  \n",
    "            feature.append(torch.from_numpy(feature_get.values).float())\n",
    "            # label.append(torch.from_numpy(np.asarray(labels)))\n",
    "        \n",
    "        \n",
    "        feature = torch.stack(feature)  \n",
    "        label = torch.from_numpy(np.asarray(self.data.iloc[index, -1]))\n",
    "        \n",
    "        return feature, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(data_train_sc, seq_length=120)\n",
    "val_dataset = CustomDataset(data_val_sc, seq_length=120)\n",
    "test_dataset = CustomDataset(data_test_sc, seq_length=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature, label = next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([120, 18]), torch.Size([]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature.shape, label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x7f585c502f70>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7f58384a8b50>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7f583855c850>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=False, drop_last=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, drop_last=True)\n",
    "\n",
    "train_dataloader, val_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature, label = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 120, 18]), torch.Size([32]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature.shape, label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM1(nn.Module):\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers, seq_length, device):\n",
    "        super(LSTM1, self).__init__()\n",
    "        self.device = device\n",
    "        self.num_classes = num_classes #number of classes\n",
    "        self.num_layers = num_layers #number of layers\n",
    "        self.input_size = input_size #input size\n",
    "        self.hidden_size = hidden_size #hidden state\n",
    "        self.seq_length = seq_length #sequence length\n",
    "        self.BatchNorm = nn.BatchNorm1d(32, affine=False)\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                          num_layers=num_layers, batch_first=True) #lstm\n",
    "        self.fc_1 =  nn.Linear(hidden_size, 32) #fully connected 1\n",
    "        self.fc = nn.Linear(32, num_classes) #fully connected last layer\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        h_0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(self.device) #hidden state Variable(\n",
    "        c_0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(self.device) #internal state Variable(\n",
    "        h_0 = self.BatchNorm(h_0)\n",
    "        c_0 = self.BatchNorm(c_0)\n",
    "        # Propagate input through LSTM\n",
    "        output, (hn, cn) = self.lstm(x, (h_0, c_0)) #lstm with input, hidden, and internal state\n",
    "        hn = hn.view(-1, self.hidden_size) #reshaping the data for Dense layer next\n",
    "        out = self.relu(hn)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc_1(out) #first Dense\n",
    "        out = self.relu(out) #relu\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out) #Final Output\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20 \n",
    "lr = 0.0001\n",
    "\n",
    "input_size = 18 \n",
    "hidden_size = 64 \n",
    "num_layers = 1 \n",
    "seq_length = 120\n",
    "num_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM1(\n",
      "  (BatchNorm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  (lstm): LSTM(18, 64, batch_first=True)\n",
      "  (fc_1): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (fc): Linear(in_features=32, out_features=3, bias=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = LSTM1(num_classes, input_size, hidden_size, num_layers, seq_length, device)\n",
    "model.to(device)\n",
    "\n",
    "print(model)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss(weight=torch.tensor([0.59, 6.69, 6.88])).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[1,4,7,10], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.classification import MulticlassF1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import shutil\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Dict, List, Tuple\n",
    "from pathlib import Path\n",
    "\n",
    "def train_step(model: torch.nn.Module, \n",
    "               dataloader: torch.utils.data.DataLoader, \n",
    "               loss_fn: torch.nn.Module, \n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               scheduler,\n",
    "               device: torch.device) -> Tuple[float, float]:\n",
    "    \n",
    "    # Put model in train mode\n",
    "    model.train()\n",
    "\n",
    "    # Setup train loss and train accuracy values\n",
    "    train_loss, train_acc, train_F1score = 0, 0, 0\n",
    "\n",
    "    # Loop through data loader data batches\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Send data to target device\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # 1. Forward pass\n",
    "        y_pred = model(X)\n",
    "\n",
    "        # 2. Calculate  and accumulate loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.item() \n",
    "\n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()        \n",
    "\n",
    "        # 4. Loss backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # Calculate and accumulate accuracy metric across all batches\n",
    "        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "        \n",
    "        metric = MulticlassF1Score(num_classes=3).to(device)\n",
    "        train_F1score += metric(y_pred_class, y)\n",
    "        \n",
    "        train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
    "\n",
    "    # Adjust metrics to get average loss and accuracy per batch \n",
    "    train_loss = train_loss / len(dataloader)\n",
    "    train_acc = train_acc / len(dataloader)\n",
    "    train_F1score = train_F1score / len(dataloader)\n",
    "    return train_loss, train_acc, train_F1score\n",
    "\n",
    "def test_step(model: torch.nn.Module, \n",
    "              dataloader: torch.utils.data.DataLoader, \n",
    "              loss_fn: torch.nn.Module,\n",
    "              device: torch.device) -> Tuple[float, float]:\n",
    "   \n",
    "    # Put model in eval mode\n",
    "    model.eval() \n",
    "\n",
    "    # Setup test loss and test accuracy values\n",
    "    val_loss, val_acc, val_F1score = 0, 0, 0\n",
    "\n",
    "    # Turn on inference context manager\n",
    "    with torch.inference_mode():\n",
    "        # Loop through DataLoader batches\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            # Send data to target device\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # 1. Forward pass\n",
    "            val_pred_logits = model(X)\n",
    "\n",
    "            # 2. Calculate and accumulate loss\n",
    "            loss = loss_fn(val_pred_logits, y)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Calculate and accumulate accuracy\n",
    "            val_pred_labels = val_pred_logits.argmax(dim=1)\n",
    "            val_acc += ((val_pred_labels == y).sum().item()/len(val_pred_labels))\n",
    "            metric = MulticlassF1Score(num_classes=3).to(device)\n",
    "            val_F1score += metric(val_pred_labels, y)\n",
    "        \n",
    "\n",
    "    # Adjust metrics to get average loss and accuracy per batch \n",
    "    val_loss = val_loss / len(dataloader)\n",
    "    val_acc = val_acc / len(dataloader)\n",
    "    val_F1score = val_F1score / len(dataloader)\n",
    "    \n",
    "    return val_loss, val_acc, val_F1score\n",
    "\n",
    "def train(model: torch.nn.Module, \n",
    "          train_dataloader: torch.utils.data.DataLoader, \n",
    "          val_dataloader: torch.utils.data.DataLoader, \n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          scheduler,\n",
    "          loss_fn: torch.nn.Module,\n",
    "          epochs: int,\n",
    "          device: torch.device) -> Dict[str, List]:\n",
    "   \n",
    "    # Create empty results dictionary\n",
    "    results = {\"train_loss\": [],\n",
    "               \"train_acc\": [],\n",
    "               \"train_F1score\": [],\n",
    "               \"val_loss\": [],\n",
    "               \"val_acc\": [],\n",
    "               \"val_F1score\": []\n",
    "    }\n",
    "    \n",
    "    # Make sure model on target device\n",
    "    model.to(device)\n",
    "    # best_loss = 3.0\n",
    "    # Loop through training and testing steps for a number of epochs\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        \n",
    "        train_loss, train_acc, train_F1score = train_step(model=model,\n",
    "                                          dataloader=train_dataloader,\n",
    "                                          loss_fn=loss_fn,\n",
    "                                          optimizer=optimizer,\n",
    "                                          scheduler=scheduler,\n",
    "                                          device=device)\n",
    "        val_loss, val_acc, val_F1score = test_step(model=model,\n",
    "          dataloader=val_dataloader,\n",
    "          loss_fn=loss_fn,\n",
    "          device=device)\n",
    "        \n",
    "        PATH = f'/notebooks/models/model_{epoch}.pth'\n",
    "        # if val_loss < best_loss:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler': scheduler.state_dict(),\n",
    "            'loss': loss_fn,\n",
    "            }, PATH)\n",
    "            # best_loss = val_loss\n",
    "        \n",
    "        # Print out what's happening\n",
    "        print(\n",
    "          f\"Epoch: {epoch+1} | \"\n",
    "          f\"train_loss: {train_loss:.4f} | \"\n",
    "          f\"train_acc: {train_acc:.4f} | \"\n",
    "          f\"train_F1score: {train_F1score:.4f} | \"  \n",
    "          f\"val_loss: {val_loss:.4f} | \"\n",
    "          f\"val_acc: {val_acc:.4f} | \"\n",
    "          f\"val_F1score: {val_F1score:.4f}\"\n",
    "        )\n",
    "        \n",
    "\n",
    "        # Update results dictionary\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"train_F1score\"].append(train_F1score)\n",
    "        results[\"val_loss\"].append(val_loss)\n",
    "        results[\"val_acc\"].append(val_acc)\n",
    "        results[\"val_F1score\"].append(val_F1score)\n",
    "\n",
    "    # Return the filled results at the end of the epochs\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10f07a50f6ce4a4086a37998cbd9a4b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 1.1017 | train_acc: 0.2760 | train_F1score: 0.2029 | val_loss: 1.0973 | val_acc: 0.3129 | val_F1score: 0.2011\n",
      "Epoch: 2 | train_loss: 1.1009 | train_acc: 0.2776 | train_F1score: 0.2041 | val_loss: 1.0973 | val_acc: 0.3130 | val_F1score: 0.2012\n",
      "Epoch: 3 | train_loss: 1.1019 | train_acc: 0.2746 | train_F1score: 0.2013 | val_loss: 1.0973 | val_acc: 0.3134 | val_F1score: 0.2014\n",
      "Epoch: 4 | train_loss: 1.1003 | train_acc: 0.2783 | train_F1score: 0.2055 | val_loss: 1.0973 | val_acc: 0.3138 | val_F1score: 0.2016\n",
      "Epoch: 5 | train_loss: 1.1015 | train_acc: 0.2784 | train_F1score: 0.2046 | val_loss: 1.0973 | val_acc: 0.3140 | val_F1score: 0.2016\n",
      "Epoch: 6 | train_loss: 1.1005 | train_acc: 0.2794 | train_F1score: 0.2049 | val_loss: 1.0973 | val_acc: 0.3141 | val_F1score: 0.2017\n",
      "Epoch: 7 | train_loss: 1.1008 | train_acc: 0.2784 | train_F1score: 0.2042 | val_loss: 1.0973 | val_acc: 0.3143 | val_F1score: 0.2018\n",
      "Epoch: 8 | train_loss: 1.1013 | train_acc: 0.2788 | train_F1score: 0.2045 | val_loss: 1.0972 | val_acc: 0.3146 | val_F1score: 0.2019\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m start_time \u001b[38;5;241m=\u001b[39m timer()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Setup training and save the results\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                   \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# End the timer and print out how long it took\u001b[39;00m\n\u001b[1;32m     20\u001b[0m end_time \u001b[38;5;241m=\u001b[39m timer()\n",
      "Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, val_dataloader, optimizer, scheduler, loss_fn, epochs, device)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(epochs)):\n\u001b[1;32m    119\u001b[0m     train_loss, train_acc, train_F1score \u001b[38;5;241m=\u001b[39m train_step(model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    120\u001b[0m                                       dataloader\u001b[38;5;241m=\u001b[39mtrain_dataloader,\n\u001b[1;32m    121\u001b[0m                                       loss_fn\u001b[38;5;241m=\u001b[39mloss_fn,\n\u001b[1;32m    122\u001b[0m                                       optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[1;32m    123\u001b[0m                                       scheduler\u001b[38;5;241m=\u001b[39mscheduler,\n\u001b[1;32m    124\u001b[0m                                       device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m--> 125\u001b[0m     val_loss, val_acc, val_F1score \u001b[38;5;241m=\u001b[39m \u001b[43mtest_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m      \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m     PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/notebooks/models/model_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m# if val_loss < best_loss:\u001b[39;00m\n",
      "Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36mtest_step\u001b[0;34m(model, dataloader, loss_fn, device)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Turn on inference context manager\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39minference_mode():\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# Loop through DataLoader batches\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch, (X, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m     71\u001b[0m         \u001b[38;5;66;03m# Send data to target device\u001b[39;00m\n\u001b[1;32m     72\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     74\u001b[0m         \u001b[38;5;66;03m# 1. Forward pass\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.9/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 530\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.9/site-packages/torch/utils/data/dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    569\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    572\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     15\u001b[0m label \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m indices:             \n\u001b[0;32m---> 17\u001b[0m     feature_get \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# feature_get, labels = self.data.iloc[index, :-1], self.data.iloc[index, -1]  \u001b[39;00m\n\u001b[1;32m     19\u001b[0m     feature\u001b[38;5;241m.\u001b[39mappend(torch\u001b[38;5;241m.\u001b[39mfrom_numpy(feature_get\u001b[38;5;241m.\u001b[39mvalues)\u001b[38;5;241m.\u001b[39mfloat())\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.9/site-packages/pandas/core/indexing.py:959\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    957\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mlist\u001b[39m(x) \u001b[38;5;28;01mif\u001b[39;00m is_iterator(x) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m key)\n\u001b[1;32m    958\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(com\u001b[38;5;241m.\u001b[39mapply_if_callable(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m key)\n\u001b[0;32m--> 959\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_is_scalar_access\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    960\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[1;32m    961\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_tuple(key)\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.9/site-packages/pandas/core/indexing.py:1432\u001b[0m, in \u001b[0;36m_iLocIndexer._is_scalar_access\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1429\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim:\n\u001b[1;32m   1430\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1432\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mall\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mis_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.9/site-packages/pandas/core/indexing.py:1432\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1429\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim:\n\u001b[1;32m   1430\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1432\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mall\u001b[39m(is_integer(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m key)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Set the random seeds\n",
    "torch.manual_seed(17)\n",
    "torch.cuda.manual_seed(17)\n",
    "\n",
    "# Start the timer\n",
    "from timeit import default_timer as timer \n",
    "start_time = timer()\n",
    "\n",
    "# Setup training and save the results\n",
    "results = train(model=model,\n",
    "                   train_dataloader=train_dataloader,\n",
    "                   val_dataloader=val_dataloader,\n",
    "                   optimizer=optimizer,\n",
    "                   scheduler=scheduler,\n",
    "                   loss_fn=loss_fn,\n",
    "                   epochs=num_epochs,\n",
    "                   device=device)\n",
    "\n",
    "# End the timer and print out how long it took\n",
    "end_time = timer()\n",
    "print(f\"[INFO] Total training time: {end_time-start_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a set of pretrained model weights\n",
    "model_load = LSTM1(num_classes, input_size, hidden_size, num_layers, seq_length, device)\n",
    "model_load.to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss(weight=torch.tensor([0.59, 6.69, 6.88])).to(device) # weight=torch.tensor([0.59, 6.69, 6.88])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "PATH = \"/notebooks/models/model_2.pth\"\n",
    "checkpoint = torch.load(PATH)\n",
    "model_load.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "scheduler.load_state_dict(checkpoint['scheduler'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seeds\n",
    "torch.manual_seed(17)\n",
    "torch.cuda.manual_seed(17)\n",
    "\n",
    "# Start the timer\n",
    "from timeit import default_timer as timer \n",
    "start_time = timer()\n",
    "\n",
    "# Setup training and save the results\n",
    "results = train(model=model_load,\n",
    "                   train_dataloader=train_dataloader,\n",
    "                   val_dataloader=val_dataloader,\n",
    "                   optimizer=optimizer,\n",
    "                   loss_fn=loss_fn,\n",
    "                   epochs=num_epochs,\n",
    "                   device=device)\n",
    "\n",
    "# End the timer and print out how long it took\n",
    "end_time = timer()\n",
    "print(f\"[INFO] Total training time: {end_time-start_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "OPqZRl9LHTOi"
   },
   "outputs": [],
   "source": [
    "def get_predictions(model, data_loader):\n",
    "    model = model.eval()\n",
    "    predictions = []\n",
    "    real_values = []\n",
    "    with torch.inference_mode():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            predictions.extend(preds)\n",
    "            real_values.extend(labels)\n",
    "    predictions = torch.as_tensor(predictions).cpu()\n",
    "    real_values = torch.as_tensor(real_values).cpu()\n",
    "    return predictions, real_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "2xuJ9h1MHTQ1"
   },
   "outputs": [],
   "source": [
    "y_pred, y_test = get_predictions(model_load, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_pred.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "6DXDOP9L5qsH"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.52      0.66     24544\n",
      "           1       0.05      0.39      0.08      1218\n",
      "           2       0.05      0.12      0.07      1278\n",
      "\n",
      "    accuracy                           0.49     27040\n",
      "   macro avg       0.34      0.34      0.27     27040\n",
      "weighted avg       0.83      0.49      0.60     27040\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['0', '1', '2']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "bwQudMUq5que"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.52      0.66     24544\n",
      "           1       0.05      0.39      0.08      1218\n",
      "           2       0.05      0.12      0.07      1278\n",
      "\n",
      "    accuracy                           0.49     27040\n",
      "   macro avg       0.34      0.34      0.27     27040\n",
      "weighted avg       0.83      0.49      0.60     27040\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['0', '1', '2']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_display = ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_display = ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMd3Ect/fzTr7BVvEXEpddh",
   "collapsed_sections": [],
   "mount_file_id": "1rNdcQWiKJkUJjU0lY52tL-h0tHgvptwU",
   "provenance": [
    {
     "file_id": "1rNdcQWiKJkUJjU0lY52tL-h0tHgvptwU",
     "timestamp": 1667057705620
    },
    {
     "file_id": "1xwP9r6GhIfwVnc8Fwq3X-C0Fo8K_jzvG",
     "timestamp": 1666933677231
    },
    {
     "file_id": "1hHbFTZ1DgD9jPHtaMtNNHlZ18EBpJsaf",
     "timestamp": 1666867613369
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "04df4f83132845aaa0b7c11d38b9e0c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c9c92ac348b0450b8b7e9a0bdf1bc4be",
      "placeholder": "​",
      "style": "IPY_MODEL_09e5b7ee180d422aa2119c099b59d1bf",
      "value": " 0/5 [00:09&lt;?, ?it/s]"
     }
    },
    "05678d723c1f4876b3b03b467a3d274e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "09e5b7ee180d422aa2119c099b59d1bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1908754ce3c3425c95abc48fae267eb2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "29d908ee76b64922966b7e59f7ed84f2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3206f533d6e24438b0530ef9e1754f0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c9d57d9bd0d94fd1b29da360aa4b1cb3",
      "max": 5,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_57858189794d4b2a9f9ab4717b16fac3",
      "value": 0
     }
    },
    "3c205f676b434ed5bd9e3b474bf57588": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "47d280c2fdaf47f7b4ab275bb3d2f093": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6cec51d9ea234d3bbb34e0efab96038b",
      "max": 1220812593,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_48eb8441708c4c42a3d471d3c10d6284",
      "value": 1220812593
     }
    },
    "48eb8441708c4c42a3d471d3c10d6284": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "57858189794d4b2a9f9ab4717b16fac3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "620dbc38a73b4ee8af1aa3cba1cb7a70": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f174c429f14b470eae48865d683dfe61",
      "placeholder": "​",
      "style": "IPY_MODEL_e2c74e8d35c942fb826bd16a7032a948",
      "value": "100%"
     }
    },
    "6cec51d9ea234d3bbb34e0efab96038b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8396a6bafe1347ee93deeba8e275883d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3c205f676b434ed5bd9e3b474bf57588",
      "placeholder": "​",
      "style": "IPY_MODEL_05678d723c1f4876b3b03b467a3d274e",
      "value": " 1.14G/1.14G [01:08&lt;00:00, 20.0MB/s]"
     }
    },
    "85bba0a438094dc09dc2ac3fa89a0805": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9562f2c0949645259fb7bc5a0d20cbf3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a66298a4692e4c0a8700ed840e2fb310": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d2c8af6bd3b54aad90e10b6ab3c53bda",
       "IPY_MODEL_3206f533d6e24438b0530ef9e1754f0f",
       "IPY_MODEL_04df4f83132845aaa0b7c11d38b9e0c7"
      ],
      "layout": "IPY_MODEL_85bba0a438094dc09dc2ac3fa89a0805"
     }
    },
    "b54e5a9b6f9b4a70a9bb56932b17c201": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_620dbc38a73b4ee8af1aa3cba1cb7a70",
       "IPY_MODEL_47d280c2fdaf47f7b4ab275bb3d2f093",
       "IPY_MODEL_8396a6bafe1347ee93deeba8e275883d"
      ],
      "layout": "IPY_MODEL_9562f2c0949645259fb7bc5a0d20cbf3"
     }
    },
    "c9c92ac348b0450b8b7e9a0bdf1bc4be": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c9d57d9bd0d94fd1b29da360aa4b1cb3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d2c8af6bd3b54aad90e10b6ab3c53bda": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_29d908ee76b64922966b7e59f7ed84f2",
      "placeholder": "​",
      "style": "IPY_MODEL_1908754ce3c3425c95abc48fae267eb2",
      "value": "  0%"
     }
    },
    "e2c74e8d35c942fb826bd16a7032a948": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f174c429f14b470eae48865d683dfe61": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
